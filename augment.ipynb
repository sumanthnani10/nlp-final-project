{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur0JE_oj-6Tz",
        "outputId": "1e313dc8-453e-42eb-8f4a-d834dcf9c479"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(14289, 15)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pip install textattack\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/nlpositionality_social-acceptability_processed.csv')\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ju3kITq_qMH",
        "outputId": "216c42a7-5c31-43b7-a209-77f4197a8801"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(291, 1)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_data=[]\n",
        "texts = df['action'].unique()\n",
        "texts.shape\n",
        "csv_file_path = './nlpositionality_social-acceptability_processed.csv'\n",
        "for j in range(len(texts)):\n",
        "   filtered_data.append([texts[j]])\n",
        "   df1=pd.DataFrame(filtered_data, columns=[\"original\"])\n",
        "# Save the DataFrame to a CSV file\n",
        "df1.to_csv(csv_file_path, index=False)\n",
        "df1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPrllIEKF2a1",
        "outputId": "ae3bc7af-c0c4-49ec-9cf0-eb9347092b9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nlpaug\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.23.5)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.31.0)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.11.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2023.11.17)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n",
            "Installing collected packages: nlpaug\n",
            "Successfully installed nlpaug-1.1.11\n"
          ]
        }
      ],
      "source": [
        "pip install nlpaug\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3Qh_fetIpHq",
        "outputId": "377bb294-ecee-4a8b-9828-2e1a7b4b7dd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                              original  \\\n",
            "0    I hate the fucking immigrants as trying to tak...   \n",
            "1    Aryan women should be forbidden by Nuhremberg/...   \n",
            "2                                   ugh these kike pos   \n",
            "3    if you must get married, you MUST marry a virg...   \n",
            "4    Western nations are infested with subhuman ani...   \n",
            "..                                                 ...   \n",
            "294  monarchs did absolutely nothing wrong' i think...   \n",
            "295  I know many people are interested in the destr...   \n",
            "296  They should have done \"Their Loss\" as it's mor...   \n",
            "297  How will your constant complaining on voat eli...   \n",
            "298  Because of the uprising level of crime committ...   \n",
            "\n",
            "                                             perturbed  \n",
            "0    [sometimes i hate the fucking irish immigrants...  \n",
            "1    [aryan white women should be forbidden by nuhr...  \n",
            "2                       [all ugh on these kike ye pos]  \n",
            "3    [if you must also get married, you must marry ...  \n",
            "4    [western nations are infested with subhuman an...  \n",
            "..                                                 ...  \n",
            "294  [monarchs did absolutely nothing wrong'i think...  \n",
            "295  [i can know why many young people are particul...  \n",
            "296  [also they should have done \" their loss \" bec...  \n",
            "297  [how much will fucking your stupid constant co...  \n",
            "298  [because of the uprising level of our crime as...  \n",
            "\n",
            "[299 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "import nlpaug.augmenter.word as naw\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you have a DataFrame 'df' with a column 'original' containing your text data\n",
        "\n",
        "# Load your data\n",
        "# For example:\n",
        "df = pd.read_csv('./noduplicates_nlpositionality_toxicity_processed.csv')\n",
        "\n",
        "# Function to apply augmentation\n",
        "def augment_text(text):\n",
        "    aug = naw.ContextualWordEmbsAug(model_path='bert-base-uncased', action=\"insert\")\n",
        "    augmented_text = aug.augment(text)\n",
        "    return augmented_text\n",
        "\n",
        "# Apply augmentation to your data\n",
        "df['perturbed'] = df['original'].apply(augment_text)\n",
        "\n",
        "# Display the original and perturbed data\n",
        "print(df[['original', 'perturbed']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HftrEBtoKYZb",
        "outputId": "472dae2d-59f6-4544-940a-4d1cc9fd667b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV file created successfully.\n"
          ]
        }
      ],
      "source": [
        "df.sample()\n",
        "df.to_csv('./augmented/augmented_nlpositionality_toxicity_processed.csv', index=False)\n",
        "\n",
        "# Confirm the file creation\n",
        "print(\"CSV file created successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ev3yNOZnKbJ0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
