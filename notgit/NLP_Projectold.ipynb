{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in c:\\users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.18 in c:\\users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages (from statsmodels) (1.25.2)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in c:\\users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages (from statsmodels) (1.11.2)\n",
      "Requirement already satisfied: pandas>=1.0 in c:\\users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages (from statsmodels) (2.0.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages (from statsmodels) (23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages (from pandas>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages (from pandas>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages (from pandas>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: six in c:\\users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Hdu_guPLf4Yv"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "def download_dataset(task, dataset_type=\"raw\"):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            - task (string): Task name (either \"social-acceptability\" or \"toxicity\")\n",
    "        Outputs:\n",
    "            - Downloads the dataset corresponding to the task name from the LabintheWild API.\n",
    "    \"\"\"\n",
    "    url = \"https://{}-litw.apps.allenai.org/api/v1/dataset?type={}\".format(\n",
    "        task if task == TOXICITY else \"delphi\",\n",
    "        dataset_type)\n",
    "    print(url)\n",
    "    response = requests.get(url)\n",
    "\n",
    "    df = pd.read_csv(StringIO(response.text), sep=\",\")\n",
    "    df.to_csv('./nlpositionality_{}_{}.csv'.format(task, dataset_type), index=False)\n",
    "\n",
    "def process_litw_data(old_df):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            - old_df (DataFrame): Joined dataset with raw demographic values, LabintheWild and dataset annotations, and model predictions\n",
    "        Outputs:\n",
    "            - df (DataFrame): Joined dataset with processed demographic values for analysis\n",
    "    \"\"\"\n",
    "    df = old_df.copy()\n",
    "    df['age'] = df['age'].apply(__process_age__)\n",
    "    df['gender'] = df['gender'].apply(__process_gender__)\n",
    "    df['ethnicity'] = df['ethnicity'].apply(__process_ethnicities__)\n",
    "    df['religion'] = df['religion'].apply(__process_religion__)\n",
    "    df['education'] = df['education'].apply(__process_education__)\n",
    "    df['native_language'] = df['native_language'].apply(lambda x: __filter_language_english__(__process_language__(x)))\n",
    "    df['country_longest'] = df['country_longest'].apply(lambda x: __filter_country_sphere__(__process_country__(x)))\n",
    "    df['country_residence'] = df['country_residence'].apply(lambda x: __filter_country_sphere__(__process_country__(x)))\n",
    "\n",
    "    return df\n",
    "\n",
    "def __process_age__(val):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            - val (int): age value to be processed\n",
    "        Outputs:\n",
    "            - (string): age group the value belongs to; \"None\" if the value is null\n",
    "    \"\"\"\n",
    "    if pd.isnull(val):\n",
    "        return 'None'\n",
    "    if val >= 10 and val < 20:\n",
    "        return '10-20'\n",
    "    if val >= 20 and val < 30:\n",
    "        return '20-30'\n",
    "    if val >= 30 and val < 40:\n",
    "        return '30-40'\n",
    "    if val >= 40 and val < 50:\n",
    "        return '40-50'\n",
    "    if val >= 50 and val < 60:\n",
    "        return '50-60'\n",
    "    if val >= 60 and val < 70:\n",
    "        return '60-70'\n",
    "    if val >= 70 and val < 80:\n",
    "        return '70-80'\n",
    "    if val >= 80:\n",
    "        return '> 80'\n",
    "    return 'None'\n",
    "\n",
    "def __process_gender__(val):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            - val (string): gender value to be processed\n",
    "        Outputs:\n",
    "            - (string): gender category the value belongs to (\"man\", \"woman\", \"non-binary\"); \"None\" if the value is null or not in one of the three categories\n",
    "    \"\"\"\n",
    "\n",
    "    if val == 'man':\n",
    "        return 'man'\n",
    "    if val == 'woman':\n",
    "        return 'woman'\n",
    "    if val == 'non-binary':\n",
    "        return 'non-binary'\n",
    "\n",
    "    #removing nans before string operations\n",
    "    if pd.isnull(val):\n",
    "        return 'None'\n",
    "\n",
    "    #we group them in non-binary for now\n",
    "    if 'agender' in val.lower():\n",
    "        return 'non-binary'\n",
    "    if 'genderfluid' in val.lower():\n",
    "        return 'non-binary'\n",
    "\n",
    "    #otherwise none, includes random fillings and no response\n",
    "    return 'None'\n",
    "\n",
    "def __process_ethnicities__(val):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            - val (string): ethnicity value to be processed\n",
    "        Outputs:\n",
    "            - (string): ethnicity category the value belongs to; \"None\" if the value is null or not in one of the predefined categories\n",
    "    \"\"\"\n",
    "    stored = ['white', 'asian, asian american', 'pacific islander, native australian', 'black, african american', 'latino/latina, hispanic', 'mixed', 'Arab-american', 'native american, american indian, alaska native']\n",
    "    if val in stored:\n",
    "        return val.split(',')[0].lower()\n",
    "    return \"None\"\n",
    "\n",
    "def __process_religion__(val):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            - val (string): religion value to be processed\n",
    "        Outputs:\n",
    "            - (string): religion category the value belongs to; \"None\" if the value is null or not in one of the predefined categories\n",
    "    \"\"\"\n",
    "\n",
    "    if pd.isnull(val):\n",
    "        return 'None'\n",
    "\n",
    "    if val.lower() in [\"roman catholic\", \"protestant\", \"orthodox\", \"christian\", \"baptist\"] or \"christian\" in val.lower():\n",
    "        return \"christian\"\n",
    "\n",
    "    if val.lower() in [\"agnostic theist\", \"spiritual\", \"paganism\"]:\n",
    "        return \"spiritual\"\n",
    "\n",
    "    if val.lower() in [\"hindu\", \"buddhist\", \"muslim\", \"jew\"]:\n",
    "        return val\n",
    "    return \"None\"\n",
    "\n",
    "def __process_education__(val):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            - val (string): education value to be processed\n",
    "        Outputs:\n",
    "            - (string): education category the value belongs to; \"None\" if the value is null or not in one of the predefined categories\n",
    "    \"\"\"\n",
    "    if pd.isnull(val):\n",
    "        return 'None'\n",
    "\n",
    "    stored = [\"college\", \"high school\", \"graduate school\", \"phd\", \"professional school\", \"pre-high school\"]\n",
    "\n",
    "    if val.lower() in stored:\n",
    "        return val\n",
    "\n",
    "    return \"None\"\n",
    "\n",
    "def __process_language__(val):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            - val (string): language value to be processed\n",
    "        Outputs:\n",
    "            - (string): language value if it is not null; \"None\" if the value is null\n",
    "    \"\"\"\n",
    "    if pd.isnull(val):\n",
    "        return 'None'\n",
    "    return val\n",
    "\n",
    "def __filter_language_english__(val):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            - val (string): language value to be processed\n",
    "        Outputs:\n",
    "            - (string): language category the value belongs to (\"english\", \"not english\"); \"None\" if the value is null or not in one of the predefined categories\n",
    "    \"\"\"\n",
    "    if val == 'None':\n",
    "        return val\n",
    "\n",
    "    if val == 'English':\n",
    "        return 'english'\n",
    "\n",
    "    return 'not english'\n",
    "\n",
    "def __process_country__(val):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            - val (string): country value to be processed\n",
    "        Outputs:\n",
    "            - (string): country value if it is not null; \"None\" if the value is null\n",
    "    \"\"\"\n",
    "    if pd.isnull(val):\n",
    "        return 'None'\n",
    "    return val\n",
    "\n",
    "def __filter_country_sphere__(val):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            - val (string): country value to be processed\n",
    "        Outputs:\n",
    "            - (string): country category the value belongs to based on cultural spheres; \"None\" if the value is null or not in one of the predefined categories\n",
    "    \"\"\"\n",
    "    spheres = json.load(open('./spheres.json'))\n",
    "    if val not in spheres:\n",
    "        return 'None'\n",
    "    return spheres[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "R2mJYcy9fxiJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # Supress pandas warnings\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "SOCIAL_ACCEPTABILITY = \"social-acceptability\"\n",
    "TOXICITY = \"toxicity\"\n",
    "\n",
    "SOCIAL_CHEM = \"socialchem\"\n",
    "DELPHI = \"delphi\"\n",
    "GPT4 = \"gpt4\"\n",
    "DYNAHATE = \"dynahate\"\n",
    "HATEROBERTA = \"hateroberta\"\n",
    "PERSPECTIVE_API = \"perspective\"\n",
    "REWIRE = \"rewire\"\n",
    "\n",
    "def get_pearson_rs(task, model_or_dataset_name, dataset_type=\"raw\"):\n",
    "    \"\"\"\n",
    "        Inputs:\n",
    "            - task (string): Task name (either \"social acceptability\" or \"toxicity\")\n",
    "            - model_or_dataset_name (string): Name of a model or dataset (either \"socialchem\", \"delphi\", \"gpt4\", \"dynahate\",\n",
    "              \"hateroberta\", \"perspective\", or \"rewire\")\n",
    "        Outputs:\n",
    "            - pearson_rs (DataFrame): DataFrame representing the Pearson's r coefficients and p-values between the dataset\n",
    "              labels/model scores and LabintheWild volunteer annotations by demographic.\n",
    "\n",
    "    \"\"\"\n",
    "    is_valid_social_acceptability = task == SOCIAL_ACCEPTABILITY and model_or_dataset_name in [SOCIAL_CHEM, DELPHI, GPT4]\n",
    "    is_valid_toxicity = task == TOXICITY and model_or_dataset_name in [GPT4, DYNAHATE, HATEROBERTA, PERSPECTIVE_API, REWIRE]\n",
    "\n",
    "    # Processed dataset is already downloaded via the API\n",
    "    if dataset_type == \"processed\" and (is_valid_toxicity or is_valid_social_acceptability):\n",
    "        df = pd.read_csv('nlpositionality_{}_processed.csv'.format(task))\n",
    "    elif dataset_type == \"raw\" and (is_valid_toxicity or is_valid_social_acceptability):\n",
    "        df = pd.read_csv('nlpositionality_{}_raw.csv'.format(task))\n",
    "        df = process_litw_data(df)\n",
    "    else:\n",
    "        raise ValueError('Invalid task name or model or dataset name')\n",
    "\n",
    "    results = {}\n",
    "    pvalues = []\n",
    "    for c in ['country_longest', 'education', 'ethnicity', 'gender', 'native_language', 'age', 'country_residence', 'religion']:\n",
    "        demo = list(df[c].unique()) # Get all the demographics under a category\n",
    "        demo.sort()\n",
    "\n",
    "        if 'None' in demo:\n",
    "            demo.remove('None')\n",
    "\n",
    "        if 'mixed' in demo:\n",
    "            demo.remove('mixed')\n",
    "\n",
    "        if 'arab-american' in demo:\n",
    "            demo.remove('arab-american')\n",
    "\n",
    "        for d in demo:\n",
    "            ndf = df[df[c] == d] # Get all the instances from a demographic group\n",
    "            dndf = __mean_df__(ndf, model_or_dataset_name) # Average responses in a demographic group\n",
    "            r, p = stats.pearsonr(dndf['litw'], dndf[model_or_dataset_name]) # Compute Pearson R values\n",
    "            results[c + '_' + d] = r\n",
    "            pvalues.append(p)\n",
    "\n",
    "    assert(len(results) == len(pvalues))\n",
    "\n",
    "    # Apply Berforroni stepwise correction\n",
    "    alpha = 0.001\n",
    "    hypotheses, pvalues, _, new_alpha = multipletests(pvalues, alpha, method='bonferroni', is_sorted=False, returnsorted=False)\n",
    "\n",
    "    data = []\n",
    "    for key, p, h in zip(results.keys(), pvalues, hypotheses):\n",
    "        # Convert p-values and Pearson's rs to strings\n",
    "        p = str(p)\n",
    "\n",
    "        value = str(round(results[key], 2))\n",
    "        if len(value) == 3:\n",
    "            value += \"0\"\n",
    "        value = value + '' + ('*' if h == True else '')\n",
    "\n",
    "        data.append({\n",
    "            \"demographic\": key,\n",
    "            \"pearson's r\": value,\n",
    "            \"p-value\": p\n",
    "        })\n",
    "\n",
    "    pearson_rs = pd.DataFrame(data=data) # Convert the data to a DataFrame\n",
    "    return pearson_rs\n",
    "\n",
    "def __mean_df__(df, model_or_dataset_name):\n",
    "    ddf = df.groupby(['action']).mean()[['litw', model_or_dataset_name]].reset_index()\n",
    "    ddf['litw'] = ddf['litw'].apply(lambda x: round(x))\n",
    "    return ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KmWTnoZyfla5",
    "outputId": "3cadcdf5-200f-4315-a3e1-35343b4737cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://delphi-litw.apps.allenai.org/api/v1/dataset?type=raw\n",
      "https://toxicity-litw.apps.allenai.org/api/v1/dataset?type=raw\n",
      "toxicity dynahate\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Could not convert 10-20 to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1490\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1489\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1490\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrouper\u001b[39m.\u001b[39m_cython_operation(\n\u001b[0;32m   1491\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maggregate\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1492\u001b[0m         values,\n\u001b[0;32m   1493\u001b[0m         how,\n\u001b[0;32m   1494\u001b[0m         axis\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39mndim \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[0;32m   1495\u001b[0m         min_count\u001b[39m=\u001b[39mmin_count,\n\u001b[0;32m   1496\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   1497\u001b[0m     )\n\u001b[0;32m   1498\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1499\u001b[0m     \u001b[39m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m     \u001b[39m# and non-applicable functions\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[39m# try to python agg\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[39m# TODO: shouldn't min_count matter?\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:959\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[1;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m ngroups \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mngroups\n\u001b[1;32m--> 959\u001b[0m \u001b[39mreturn\u001b[39;00m cy_op\u001b[39m.\u001b[39mcython_operation(\n\u001b[0;32m    960\u001b[0m     values\u001b[39m=\u001b[39mvalues,\n\u001b[0;32m    961\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[0;32m    962\u001b[0m     min_count\u001b[39m=\u001b[39mmin_count,\n\u001b[0;32m    963\u001b[0m     comp_ids\u001b[39m=\u001b[39mids,\n\u001b[0;32m    964\u001b[0m     ngroups\u001b[39m=\u001b[39mngroups,\n\u001b[0;32m    965\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    966\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:657\u001b[0m, in \u001b[0;36mWrappedCythonOp.cython_operation\u001b[1;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ea_wrap_cython_operation(\n\u001b[0;32m    650\u001b[0m         values,\n\u001b[0;32m    651\u001b[0m         min_count\u001b[39m=\u001b[39mmin_count,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    655\u001b[0m     )\n\u001b[1;32m--> 657\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cython_op_ndim_compat(\n\u001b[0;32m    658\u001b[0m     values,\n\u001b[0;32m    659\u001b[0m     min_count\u001b[39m=\u001b[39mmin_count,\n\u001b[0;32m    660\u001b[0m     ngroups\u001b[39m=\u001b[39mngroups,\n\u001b[0;32m    661\u001b[0m     comp_ids\u001b[39m=\u001b[39mcomp_ids,\n\u001b[0;32m    662\u001b[0m     mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    663\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    664\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:497\u001b[0m, in \u001b[0;36mWrappedCythonOp._cython_op_ndim_compat\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39mT\n\u001b[1;32m--> 497\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_cython_op(\n\u001b[0;32m    498\u001b[0m     values,\n\u001b[0;32m    499\u001b[0m     min_count\u001b[39m=\u001b[39mmin_count,\n\u001b[0;32m    500\u001b[0m     ngroups\u001b[39m=\u001b[39mngroups,\n\u001b[0;32m    501\u001b[0m     comp_ids\u001b[39m=\u001b[39mcomp_ids,\n\u001b[0;32m    502\u001b[0m     mask\u001b[39m=\u001b[39mmask,\n\u001b[0;32m    503\u001b[0m     result_mask\u001b[39m=\u001b[39mresult_mask,\n\u001b[0;32m    504\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    505\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:541\u001b[0m, in \u001b[0;36mWrappedCythonOp._call_cython_op\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[0;32m    540\u001b[0m out_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_output_shape(ngroups, values)\n\u001b[1;32m--> 541\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_cython_function(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkind, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhow, values\u001b[39m.\u001b[39;49mdtype, is_numeric)\n\u001b[0;32m    542\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_cython_vals(values)\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:173\u001b[0m, in \u001b[0;36mWrappedCythonOp._get_cython_function\u001b[1;34m(cls, kind, how, dtype, is_numeric)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m f\u001b[39m.\u001b[39m__signatures__:\n\u001b[0;32m    172\u001b[0m     \u001b[39m# raise NotImplementedError here rather than TypeError later\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    174\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfunction is not implemented for this dtype: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    175\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[how->\u001b[39m\u001b[39m{\u001b[39;00mhow\u001b[39m}\u001b[39;00m\u001b[39m,dtype->\u001b[39m\u001b[39m{\u001b[39;00mdtype_str\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m f\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: function is not implemented for this dtype: [how->mean,dtype->object]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\nanops.py:1692\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1691\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1692\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39;49m(x)\n\u001b[0;32m   1693\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1694\u001b[0m     \u001b[39m# e.g. \"1+1j\" or \"foo\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '10-20'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\nanops.py:1696\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1695\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1696\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mcomplex\u001b[39;49m(x)\n\u001b[0;32m   1697\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m   1698\u001b[0m     \u001b[39m# e.g. \"foo\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: complex() arg is a malformed string",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\suman\\OneDrive\\Documents\\Mason Docs\\Assignments\\678\\Project\\NLP_Project.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/suman/OneDrive/Documents/Mason%20Docs/Assignments/678/Project/NLP_Project.ipynb#W3sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/suman/OneDrive/Documents/Mason%20Docs/Assignments/678/Project/NLP_Project.ipynb#W3sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     dataset_type \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m# processed\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/suman/OneDrive/Documents/Mason%20Docs/Assignments/678/Project/NLP_Project.ipynb#W3sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     run_experiments(dataset_type)\n",
      "\u001b[1;32mc:\\Users\\suman\\OneDrive\\Documents\\Mason Docs\\Assignments\\678\\Project\\NLP_Project.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/suman/OneDrive/Documents/Mason%20Docs/Assignments/678/Project/NLP_Project.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mfor\u001b[39;00m task, dataset_or_model \u001b[39min\u001b[39;00m experiments:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/suman/OneDrive/Documents/Mason%20Docs/Assignments/678/Project/NLP_Project.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         \u001b[39mprint\u001b[39m(task, dataset_or_model)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/suman/OneDrive/Documents/Mason%20Docs/Assignments/678/Project/NLP_Project.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         df \u001b[39m=\u001b[39m get_pearson_rs(task, dataset_or_model, dataset_type\u001b[39m=\u001b[39;49mdataset_type)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/suman/OneDrive/Documents/Mason%20Docs/Assignments/678/Project/NLP_Project.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m#         print(df)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/suman/OneDrive/Documents/Mason%20Docs/Assignments/678/Project/NLP_Project.ipynb#W3sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         df\u001b[39m.\u001b[39mto_csv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mtask\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mdataset_or_model\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mdataset_type\u001b[39m}\u001b[39;00m\u001b[39m_output.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\suman\\OneDrive\\Documents\\Mason Docs\\Assignments\\678\\Project\\NLP_Project.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/suman/OneDrive/Documents/Mason%20Docs/Assignments/678/Project/NLP_Project.ipynb#W3sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# print(\"ndf\",ndf)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/suman/OneDrive/Documents/Mason%20Docs/Assignments/678/Project/NLP_Project.ipynb#W3sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m ndf\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39mndf.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/suman/OneDrive/Documents/Mason%20Docs/Assignments/678/Project/NLP_Project.ipynb#W3sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m dndf \u001b[39m=\u001b[39m __mean_df__(ndf, model_or_dataset_name) \u001b[39m# Average responses in a demographic group\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/suman/OneDrive/Documents/Mason%20Docs/Assignments/678/Project/NLP_Project.ipynb#W3sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39m# print(\"dndf\",dndf)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/suman/OneDrive/Documents/Mason%20Docs/Assignments/678/Project/NLP_Project.ipynb#W3sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m dndf\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39mdndf.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\suman\\OneDrive\\Documents\\Mason Docs\\Assignments\\678\\Project\\NLP_Project.ipynb Cell 4\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/suman/OneDrive/Documents/Mason%20Docs/Assignments/678/Project/NLP_Project.ipynb#W3sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__mean_df__\u001b[39m(df, model_or_dataset_name):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/suman/OneDrive/Documents/Mason%20Docs/Assignments/678/Project/NLP_Project.ipynb#W3sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m     ddf \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mgroupby([\u001b[39m'\u001b[39;49m\u001b[39maction\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m.\u001b[39;49mmean()[[\u001b[39m'\u001b[39m\u001b[39mlitw\u001b[39m\u001b[39m'\u001b[39m, model_or_dataset_name]]\u001b[39m.\u001b[39mreset_index()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/suman/OneDrive/Documents/Mason%20Docs/Assignments/678/Project/NLP_Project.ipynb#W3sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m     ddf[\u001b[39m'\u001b[39m\u001b[39mlitw\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m ddf[\u001b[39m'\u001b[39m\u001b[39mlitw\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mround\u001b[39m(x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/suman/OneDrive/Documents/Mason%20Docs/Assignments/678/Project/NLP_Project.ipynb#W3sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m ddf\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1855\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[0;32m   1854\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1855\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cython_agg_general(\n\u001b[0;32m   1856\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1857\u001b[0m         alt\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m x: Series(x)\u001b[39m.\u001b[39;49mmean(numeric_only\u001b[39m=\u001b[39;49mnumeric_only),\n\u001b[0;32m   1858\u001b[0m         numeric_only\u001b[39m=\u001b[39;49mnumeric_only,\n\u001b[0;32m   1859\u001b[0m     )\n\u001b[0;32m   1860\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgroupby\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1507\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   1503\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_agg_py_fallback(values, ndim\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39mndim, alt\u001b[39m=\u001b[39malt)\n\u001b[0;32m   1505\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m-> 1507\u001b[0m new_mgr \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mgrouped_reduce(array_func)\n\u001b[0;32m   1508\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[0;32m   1509\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1503\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1499\u001b[0m \u001b[39mif\u001b[39;00m blk\u001b[39m.\u001b[39mis_object:\n\u001b[0;32m   1500\u001b[0m     \u001b[39m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[39m#  while others do not.\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[39mfor\u001b[39;00m sb \u001b[39min\u001b[39;00m blk\u001b[39m.\u001b[39m_split():\n\u001b[1;32m-> 1503\u001b[0m         applied \u001b[39m=\u001b[39m sb\u001b[39m.\u001b[39;49mapply(func)\n\u001b[0;32m   1504\u001b[0m         result_blocks \u001b[39m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m   1505\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:329\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m    324\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, func, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[Block]:\n\u001b[0;32m    325\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[39m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[39m    one\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    331\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1503\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1490\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrouper\u001b[39m.\u001b[39m_cython_operation(\n\u001b[0;32m   1491\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maggregate\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1492\u001b[0m         values,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1496\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   1497\u001b[0m     )\n\u001b[0;32m   1498\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[0;32m   1499\u001b[0m     \u001b[39m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m     \u001b[39m# and non-applicable functions\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m     \u001b[39m# try to python agg\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m     \u001b[39m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[1;32m-> 1503\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_agg_py_fallback(values, ndim\u001b[39m=\u001b[39;49mdata\u001b[39m.\u001b[39;49mndim, alt\u001b[39m=\u001b[39;49malt)\n\u001b[0;32m   1505\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1457\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1452\u001b[0m     ser \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[:, \u001b[39m0\u001b[39m]\n\u001b[0;32m   1454\u001b[0m \u001b[39m# We do not get here with UDFs, so we know that our dtype\u001b[39;00m\n\u001b[0;32m   1455\u001b[0m \u001b[39m#  should always be preserved by the implemented aggregations\u001b[39;00m\n\u001b[0;32m   1456\u001b[0m \u001b[39m# TODO: Is this exactly right; see WrappedCythonOp get_result_dtype?\u001b[39;00m\n\u001b[1;32m-> 1457\u001b[0m res_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49magg_series(ser, alt, preserve_dtype\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   1459\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(values, Categorical):\n\u001b[0;32m   1460\u001b[0m     \u001b[39m# Because we only get here with known dtype-preserving\u001b[39;00m\n\u001b[0;32m   1461\u001b[0m     \u001b[39m#  reductions, we cast back to Categorical.\u001b[39;00m\n\u001b[0;32m   1462\u001b[0m     \u001b[39m# TODO: if we ever get \"rank\" working, exclude it here.\u001b[39;00m\n\u001b[0;32m   1463\u001b[0m     res_values \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(values)\u001b[39m.\u001b[39m_from_sequence(res_values, dtype\u001b[39m=\u001b[39mvalues\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:994\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(obj) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39m_values, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m    988\u001b[0m     \u001b[39m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[0;32m    989\u001b[0m     \u001b[39m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[0;32m    990\u001b[0m     \u001b[39m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[0;32m    991\u001b[0m     \u001b[39m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[0;32m    992\u001b[0m     preserve_dtype \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 994\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_aggregate_series_pure_python(obj, func)\n\u001b[0;32m    996\u001b[0m npvalues \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    997\u001b[0m \u001b[39mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:1015\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m   1012\u001b[0m splitter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_splitter(obj, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m   1014\u001b[0m \u001b[39mfor\u001b[39;00m i, group \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(splitter):\n\u001b[1;32m-> 1015\u001b[0m     res \u001b[39m=\u001b[39m func(group)\n\u001b[0;32m   1016\u001b[0m     res \u001b[39m=\u001b[39m libreduction\u001b[39m.\u001b[39mextract_result(res)\n\u001b[0;32m   1018\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m initialized:\n\u001b[0;32m   1019\u001b[0m         \u001b[39m# We only do this validation on the first iteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1857\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs)\n\u001b[0;32m   1854\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1855\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   1856\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m-> 1857\u001b[0m         alt\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: Series(x)\u001b[39m.\u001b[39;49mmean(numeric_only\u001b[39m=\u001b[39;49mnumeric_only),\n\u001b[0;32m   1858\u001b[0m         numeric_only\u001b[39m=\u001b[39mnumeric_only,\n\u001b[0;32m   1859\u001b[0m     )\n\u001b[0;32m   1860\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgroupby\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\generic.py:11556\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11539\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[0;32m  11540\u001b[0m     _num_doc,\n\u001b[0;32m  11541\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReturn the mean of the values over the requested axis.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11554\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m  11555\u001b[0m ):\n\u001b[1;32m> 11556\u001b[0m     \u001b[39mreturn\u001b[39;00m NDFrame\u001b[39m.\u001b[39mmean(\u001b[39mself\u001b[39m, axis, skipna, numeric_only, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\generic.py:11201\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11194\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean\u001b[39m(\n\u001b[0;32m  11195\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m  11196\u001b[0m     axis: Axis \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11199\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m  11200\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[1;32m> 11201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stat_function(\n\u001b[0;32m  11202\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m, nanops\u001b[39m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m  11203\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\generic.py:11158\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11154\u001b[0m     nv\u001b[39m.\u001b[39mvalidate_stat_func((), kwargs, fname\u001b[39m=\u001b[39mname)\n\u001b[0;32m  11156\u001b[0m validate_bool_kwarg(skipna, \u001b[39m\"\u001b[39m\u001b[39mskipna\u001b[39m\u001b[39m\"\u001b[39m, none_allowed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m> 11158\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reduce(\n\u001b[0;32m  11159\u001b[0m     func, name\u001b[39m=\u001b[39;49mname, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, numeric_only\u001b[39m=\u001b[39;49mnumeric_only\n\u001b[0;32m  11160\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\series.py:4670\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4665\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   4666\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSeries.\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m does not allow \u001b[39m\u001b[39m{\u001b[39;00mkwd_name\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mnumeric_only\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4667\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwith non-numeric dtypes.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4668\u001b[0m     )\n\u001b[0;32m   4669\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 4670\u001b[0m     \u001b[39mreturn\u001b[39;00m op(delegate, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\nanops.py:96\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(invalid\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m---> 96\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39m# we want to transform an object array\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[39m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[39m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[39m# object arrays that contain strings\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[39mif\u001b[39;00m is_object_dtype(args[\u001b[39m0\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\nanops.py:158\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    156\u001b[0m         result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    157\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    160\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\nanops.py:421\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[39mif\u001b[39;00m datetimelike \u001b[39mand\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    419\u001b[0m     mask \u001b[39m=\u001b[39m isna(values)\n\u001b[1;32m--> 421\u001b[0m result \u001b[39m=\u001b[39m func(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, mask\u001b[39m=\u001b[39mmask, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    423\u001b[0m \u001b[39mif\u001b[39;00m datetimelike:\n\u001b[0;32m    424\u001b[0m     result \u001b[39m=\u001b[39m _wrap_results(result, orig_values\u001b[39m.\u001b[39mdtype, fill_value\u001b[39m=\u001b[39miNaT)\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\nanops.py:727\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    724\u001b[0m     dtype_count \u001b[39m=\u001b[39m dtype\n\u001b[0;32m    726\u001b[0m count \u001b[39m=\u001b[39m _get_counts(values\u001b[39m.\u001b[39mshape, mask, axis, dtype\u001b[39m=\u001b[39mdtype_count)\n\u001b[1;32m--> 727\u001b[0m the_sum \u001b[39m=\u001b[39m _ensure_numeric(values\u001b[39m.\u001b[39;49msum(axis, dtype\u001b[39m=\u001b[39;49mdtype_sum))\n\u001b[0;32m    729\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mgetattr\u001b[39m(the_sum, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    730\u001b[0m     count \u001b[39m=\u001b[39m cast(np\u001b[39m.\u001b[39mndarray, count)\n",
      "File \u001b[1;32mc:\\Users\\suman\\anaconda3\\envs\\ccr\\lib\\site-packages\\pandas\\core\\nanops.py:1699\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1696\u001b[0m             x \u001b[39m=\u001b[39m \u001b[39mcomplex\u001b[39m(x)\n\u001b[0;32m   1697\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m   1698\u001b[0m             \u001b[39m# e.g. \"foo\"\u001b[39;00m\n\u001b[1;32m-> 1699\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not convert \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m to numeric\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert 10-20 to numeric"
     ]
    }
   ],
   "source": [
    "experiments = [\n",
    "    # (SOCIAL_ACCEPTABILITY, SOCIAL_CHEM),\n",
    "#     (SOCIAL_ACCEPTABILITY, DELPHI),\n",
    "#     (SOCIAL_ACCEPTABILITY, GPT4),\n",
    "    (TOXICITY, DYNAHATE),\n",
    "#     (TOXICITY, PERSPECTIVE_API),\n",
    "#     (TOXICITY, REWIRE),\n",
    "#     (TOXICITY, HATEROBERTA),\n",
    "#     (TOXICITY, GPT4),\n",
    "]\n",
    "\n",
    "def run_experiments(dataset_type):\n",
    "    download_dataset(SOCIAL_ACCEPTABILITY, dataset_type=dataset_type)\n",
    "    download_dataset(TOXICITY, dataset_type=dataset_type)\n",
    "\n",
    "    for task, dataset_or_model in experiments:\n",
    "        print(task, dataset_or_model)\n",
    "        df = get_pearson_rs(task, dataset_or_model, dataset_type=dataset_type)\n",
    "#         print(df)\n",
    "        df.to_csv(f\"{task}_{dataset_or_model}_{dataset_type}_output.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_type = \"raw\" # processed\n",
    "    run_experiments(dataset_type)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
