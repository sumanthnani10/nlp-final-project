{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import requests\n",
        "from io import StringIO\n",
        "\n",
        "def download_dataset(task, dataset_type=\"raw\"):\n",
        "    \"\"\"\n",
        "        Inputs:\n",
        "            - task (string): Task name (either \"social-acceptability\" or \"toxicity\")\n",
        "        Outputs:\n",
        "            - Downloads the dataset corresponding to the task name from the LabintheWild API.\n",
        "    \"\"\"\n",
        "    url = \"https://{}-litw.apps.allenai.org/api/v1/dataset?type={}\".format(\n",
        "        task if task == nlpositionality.TOXICITY else \"delphi\",\n",
        "        dataset_type)\n",
        "    response = requests.get(url)\n",
        "\n",
        "    df = pd.read_csv(StringIO(response.text), sep=\",\")\n",
        "    df.to_csv('./data/nlpositionality_{}_{}.csv'.format(task, dataset_type), index=False)\n",
        "\n",
        "def process_litw_data(old_df):\n",
        "    \"\"\"\n",
        "        Inputs:\n",
        "            - old_df (DataFrame): Joined dataset with raw demographic values, LabintheWild and dataset annotations, and model predictions\n",
        "        Outputs:\n",
        "            - df (DataFrame): Joined dataset with processed demographic values for analysis\n",
        "    \"\"\"\n",
        "    df = old_df.copy()\n",
        "    df['age'] = df['age'].apply(__process_age__)\n",
        "    df['gender'] = df['gender'].apply(__process_gender__)\n",
        "    df['ethnicity'] = df['ethnicity'].apply(__process_ethnicities__)\n",
        "    df['religion'] = df['religion'].apply(__process_religion__)\n",
        "    df['education'] = df['education'].apply(__process_education__)\n",
        "    df['native_language'] = df['native_language'].apply(lambda x: __filter_language_english__(__process_language__(x)))\n",
        "    df['country_longest'] = df['country_longest'].apply(lambda x: __filter_country_sphere__(__process_country__(x)))\n",
        "    df['country_residence'] = df['country_residence'].apply(lambda x: __filter_country_sphere__(__process_country__(x)))\n",
        "\n",
        "    return df\n",
        "\n",
        "def __process_age__(val):\n",
        "    \"\"\"\n",
        "        Inputs:\n",
        "            - val (int): age value to be processed\n",
        "        Outputs:\n",
        "            - (string): age group the value belongs to; \"None\" if the value is null\n",
        "    \"\"\"\n",
        "    if pd.isnull(val):\n",
        "        return 'None'\n",
        "    if val >= 10 and val < 20:\n",
        "        return '10-20'\n",
        "    if val >= 20 and val < 30:\n",
        "        return '20-30'\n",
        "    if val >= 30 and val < 40:\n",
        "        return '30-40'\n",
        "    if val >= 40 and val < 50:\n",
        "        return '40-50'\n",
        "    if val >= 50 and val < 60:\n",
        "        return '50-60'\n",
        "    if val >= 60 and val < 70:\n",
        "        return '60-70'\n",
        "    if val >= 70 and val < 80:\n",
        "        return '70-80'\n",
        "    if val >= 80:\n",
        "        return '> 80'\n",
        "    return 'None'\n",
        "\n",
        "def __process_gender__(val):\n",
        "    \"\"\"\n",
        "        Inputs:\n",
        "            - val (string): gender value to be processed\n",
        "        Outputs:\n",
        "            - (string): gender category the value belongs to (\"man\", \"woman\", \"non-binary\"); \"None\" if the value is null or not in one of the three categories\n",
        "    \"\"\"\n",
        "\n",
        "    if val == 'man':\n",
        "        return 'man'\n",
        "    if val == 'woman':\n",
        "        return 'woman'\n",
        "    if val == 'non-binary':\n",
        "        return 'non-binary'\n",
        "\n",
        "    #removing nans before string operations\n",
        "    if pd.isnull(val):\n",
        "        return 'None'\n",
        "\n",
        "    #we group them in non-binary for now\n",
        "    if 'agender' in val.lower():\n",
        "        return 'non-binary'\n",
        "    if 'genderfluid' in val.lower():\n",
        "        return 'non-binary'\n",
        "\n",
        "    #otherwise none, includes random fillings and no response\n",
        "    return 'None'\n",
        "\n",
        "def __process_ethnicities__(val):\n",
        "    \"\"\"\n",
        "        Inputs:\n",
        "            - val (string): ethnicity value to be processed\n",
        "        Outputs:\n",
        "            - (string): ethnicity category the value belongs to; \"None\" if the value is null or not in one of the predefined categories\n",
        "    \"\"\"\n",
        "    stored = ['white', 'asian, asian american', 'pacific islander, native australian', 'black, african american', 'latino/latina, hispanic', 'mixed', 'Arab-american', 'native american, american indian, alaska native']\n",
        "    if val in stored:\n",
        "        return val.split(',')[0].lower()\n",
        "    return \"None\"\n",
        "\n",
        "def __process_religion__(val):\n",
        "    \"\"\"\n",
        "        Inputs:\n",
        "            - val (string): religion value to be processed\n",
        "        Outputs:\n",
        "            - (string): religion category the value belongs to; \"None\" if the value is null or not in one of the predefined categories\n",
        "    \"\"\"\n",
        "\n",
        "    if pd.isnull(val):\n",
        "        return 'None'\n",
        "\n",
        "    if val.lower() in [\"roman catholic\", \"protestant\", \"orthodox\", \"christian\", \"baptist\"] or \"christian\" in val.lower():\n",
        "        return \"christian\"\n",
        "\n",
        "    if val.lower() in [\"agnostic theist\", \"spiritual\", \"paganism\"]:\n",
        "        return \"spiritual\"\n",
        "\n",
        "    if val.lower() in [\"hindu\", \"buddhist\", \"muslim\", \"jew\"]:\n",
        "        return val\n",
        "    return \"None\"\n",
        "\n",
        "def __process_education__(val):\n",
        "    \"\"\"\n",
        "        Inputs:\n",
        "            - val (string): education value to be processed\n",
        "        Outputs:\n",
        "            - (string): education category the value belongs to; \"None\" if the value is null or not in one of the predefined categories\n",
        "    \"\"\"\n",
        "    if pd.isnull(val):\n",
        "        return 'None'\n",
        "\n",
        "    stored = [\"college\", \"high school\", \"graduate school\", \"phd\", \"professional school\", \"pre-high school\"]\n",
        "\n",
        "    if val.lower() in stored:\n",
        "        return val\n",
        "\n",
        "    return \"None\"\n",
        "\n",
        "def __process_language__(val):\n",
        "    \"\"\"\n",
        "        Inputs:\n",
        "            - val (string): language value to be processed\n",
        "        Outputs:\n",
        "            - (string): language value if it is not null; \"None\" if the value is null\n",
        "    \"\"\"\n",
        "    if pd.isnull(val):\n",
        "        return 'None'\n",
        "    return val\n",
        "\n",
        "def __filter_language_english__(val):\n",
        "    \"\"\"\n",
        "        Inputs:\n",
        "            - val (string): language value to be processed\n",
        "        Outputs:\n",
        "            - (string): language category the value belongs to (\"english\", \"not english\"); \"None\" if the value is null or not in one of the predefined categories\n",
        "    \"\"\"\n",
        "    if val == 'None':\n",
        "        return val\n",
        "\n",
        "    if val == 'English':\n",
        "        return 'english'\n",
        "\n",
        "    return 'not english'\n",
        "\n",
        "def __process_country__(val):\n",
        "    \"\"\"\n",
        "        Inputs:\n",
        "            - val (string): country value to be processed\n",
        "        Outputs:\n",
        "            - (string): country value if it is not null; \"None\" if the value is null\n",
        "    \"\"\"\n",
        "    if pd.isnull(val):\n",
        "        return 'None'\n",
        "    return val\n",
        "\n",
        "def __filter_country_sphere__(val):\n",
        "    \"\"\"\n",
        "        Inputs:\n",
        "            - val (string): country value to be processed\n",
        "        Outputs:\n",
        "            - (string): country category the value belongs to based on cultural spheres; \"None\" if the value is null or not in one of the predefined categories\n",
        "    \"\"\"\n",
        "    spheres = json.load(open('./data/spheres.json'))\n",
        "    if val not in spheres:\n",
        "        return 'None'\n",
        "    return spheres[val]"
      ],
      "metadata": {
        "id": "Hdu_guPLf4Yv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning) # Supress pandas warnings\n",
        "from scipy import stats\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "\n",
        "SOCIAL_ACCEPTABILITY = \"social-acceptability\"\n",
        "TOXICITY = \"toxicity\"\n",
        "\n",
        "SOCIAL_CHEM = \"socialchem\"\n",
        "DELPHI = \"delphi\"\n",
        "GPT4 = \"gpt4\"\n",
        "DYNAHATE = \"dynahate\"\n",
        "HATEROBERTA = \"hateroberta\"\n",
        "PERSPECTIVE_API = \"perspective\"\n",
        "REWIRE = \"rewire\"\n",
        "\n",
        "def get_pearson_rs(task, model_or_dataset_name, dataset_type=\"raw\"):\n",
        "    \"\"\"\n",
        "        Inputs:\n",
        "            - task (string): Task name (either \"social acceptability\" or \"toxicity\")\n",
        "            - model_or_dataset_name (string): Name of a model or dataset (either \"socialchem\", \"delphi\", \"gpt4\", \"dynahate\",\n",
        "              \"hateroberta\", \"perspective\", or \"rewire\")\n",
        "        Outputs:\n",
        "            - pearson_rs (DataFrame): DataFrame representing the Pearson's r coefficients and p-values between the dataset\n",
        "              labels/model scores and LabintheWild volunteer annotations by demographic.\n",
        "\n",
        "    \"\"\"\n",
        "    is_valid_social_acceptability = task == SOCIAL_ACCEPTABILITY and model_or_dataset_name in [SOCIAL_CHEM, DELPHI, GPT4]\n",
        "    is_valid_toxicity = task == TOXICITY and model_or_dataset_name in [GPT4, DYNAHATE, HATEROBERTA, PERSPECTIVE_API, REWIRE]\n",
        "\n",
        "    # Processed dataset is already downloaded via the API\n",
        "    if dataset_type == \"processed\" and (is_valid_toxicity or is_valid_social_acceptability):\n",
        "        df = pd.read_csv('data/nlpositionality_{}_processed.csv'.format(task))\n",
        "    elif dataset_type == \"raw\" and (is_valid_toxicity or is_valid_social_acceptability):\n",
        "        df = pd.read_csv('data/nlpositionality_{}_raw.csv'.format(task))\n",
        "        df = utils.process_litw_data(df)\n",
        "    else:\n",
        "        raise ValueError('Invalid task name or model or dataset name')\n",
        "\n",
        "    results = {}\n",
        "    pvalues = []\n",
        "    for c in ['country_longest', 'education', 'ethnicity', 'gender', 'native_language', 'age', 'country_residence', 'religion']:\n",
        "        demo = list(df[c].unique()) # Get all the demographics under a category\n",
        "        demo.sort()\n",
        "\n",
        "        if 'None' in demo:\n",
        "            demo.remove('None')\n",
        "\n",
        "        if 'mixed' in demo:\n",
        "            demo.remove('mixed')\n",
        "\n",
        "        if 'arab-american' in demo:\n",
        "            demo.remove('arab-american')\n",
        "\n",
        "        for d in demo:\n",
        "            ndf = df[df[c] == d] # Get all the instances from a demographic group\n",
        "            dndf = __mean_df__(ndf, model_or_dataset_name) # Average responses in a demographic group\n",
        "            r, p = stats.pearsonr(dndf['litw'], dndf[model_or_dataset_name]) # Compute Pearson R values\n",
        "\n",
        "            results[c + '_' + d] = r\n",
        "            pvalues.append(p)\n",
        "\n",
        "    assert(len(results) == len(pvalues))\n",
        "\n",
        "    # Apply Berforroni stepwise correction\n",
        "    alpha = 0.001\n",
        "    hypotheses, pvalues, _, new_alpha = multipletests(pvalues, alpha, method='bonferroni', is_sorted=False, returnsorted=False)\n",
        "\n",
        "    data = []\n",
        "    for key, p, h in zip(results.keys(), pvalues, hypotheses):\n",
        "        # Convert p-values and Pearson's rs to strings\n",
        "        p = str(p)\n",
        "\n",
        "        value = str(round(results[key], 2))\n",
        "        if len(value) == 3:\n",
        "            value += \"0\"\n",
        "        value = value + '' + ('*' if h == True else '')\n",
        "\n",
        "        data.append({\n",
        "            \"demographic\": key,\n",
        "            \"pearson's r\": value,\n",
        "            \"p-value\": p\n",
        "        })\n",
        "\n",
        "    pearson_rs = pd.DataFrame(data=data) # Convert the data to a DataFrame\n",
        "    return pearson_rs\n",
        "\n",
        "def __mean_df__(df, model_or_dataset_name):\n",
        "    ddf = df.groupby(['action']).mean()[['litw', model_or_dataset_name]].reset_index()\n",
        "    ddf['litw'] = ddf['litw'].apply(lambda x: round(x))\n",
        "    return ddf"
      ],
      "metadata": {
        "id": "R2mJYcy9fxiJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmWTnoZyfla5"
      },
      "outputs": [],
      "source": [
        "experiments = [\n",
        "    (SOCIAL_ACCEPTABILITY, SOCIAL_CHEM),\n",
        "    (SOCIAL_ACCEPTABILITY, DELPHI),\n",
        "    (SOCIAL_ACCEPTABILITY, GPT4),\n",
        "    (TOXICITY, DYNAHATE),\n",
        "    (TOXICITY, PERSPECTIVE_API),\n",
        "    (TOXICITY, REWIRE),\n",
        "    (TOXICITY, HATEROBERTA),\n",
        "    (TOXICITY, GPT4),\n",
        "]\n",
        "\n",
        "def run_experiments(dataset_type):\n",
        "    download_dataset(SOCIAL_ACCEPTABILITY, dataset_type=dataset_type)\n",
        "    download_dataset(TOXICITY, dataset_type=dataset_type)\n",
        "\n",
        "    for task, dataset_or_model in experiments:\n",
        "        print(task, dataset_or_model)\n",
        "        df = get_pearson_rs(task, dataset_or_model, dataset_type=dataset_type)\n",
        "        print(df)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    dataset_type = \"raw\" # Dataset with raw demographic values\n",
        "    # dataset_type = \"processed\" # Dataset with processed demographic values\n",
        "    run_experiments(dataset_type)"
      ]
    }
  ]
}